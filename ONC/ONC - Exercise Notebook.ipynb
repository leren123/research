{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By: Rino Hilman\n",
    "* Email: rinohilman@yahoo.com\n",
    "* Reference: Detection of False Investment Strategies using Unsupervised Learning Methods by Marcos Lopez de Prado and Michael J. Lewis \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Optimal Number of Clusters (ONC)\n",
    "\n",
    "* Warning : written for python 3\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Optimal Number of Clusters algorithm has a purpose to detect optimal number of K-Means clusters using feature correlation matrix and silhouette scores.\n",
    "This implementation is based on 'Detection of False Investment Strategies using Unsupervised Learning Methods' https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3167017\n",
    "\n",
    "The result of this algorithm is a tupple that contains:\n",
    "\n",
    "    Correlation Matrix\n",
    "    Optimized Clusters\n",
    "    Silhouette Scores\n",
    "\n",
    "Correlation Matrix show the matrix that are sorted by their relevance. Optimized Clustres show the optimal number of clustres and each of the culsters' contents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "This notebook shows the modified K-Means clustering or known as ONC algorithm preceded by a random correlation matrix generator.\n",
    "Both of the algorithms are shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercises contain the working codes that represent the ONC algorithm and the random correlation matrix generator. All codes can be executed and will work accordingly. The first step is to import all of the necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.linalg import block_diag \n",
    "from sklearn.utils import check_random_state "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Correlation Block - Matrices Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function getCovSub has a purpose to find the Sub Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCovSub(nObs,nCols,sigma,random_state=None): \n",
    "    # Sub covariance matrix \n",
    "    rng = check_random_state(random_state) \n",
    "    if nCols==1:return np.ones((1,1)) \n",
    "    ar0=rng.normal(size=(nObs,1))     \n",
    "    ar0=np.repeat(ar0,nCols,axis=1)     \n",
    "    ar0+=rng.normal(scale=sigma,size=ar0.shape)     \n",
    "    ar0=np.cov(ar0,rowvar=False)     \n",
    "    return ar0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function getRndBlockCov generates a random covariance matrix with a given number of blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRndBlockCov(nCols,nBlocks,minBlockSize=1,sigma=1.,random_state=None):\n",
    "    # Generate a random covariance matrix with a given number of blocks     \n",
    "    rng = check_random_state(random_state)     \n",
    "    parts=rng.choice(range(1,nCols-(minBlockSize-1)*nBlocks),nBlocks-1,replace=False)     \n",
    "    parts.sort()     \n",
    "    parts=np.append(parts,nCols-(minBlockSize-1)*nBlocks)     \n",
    "    parts=np.append(parts[0],np.diff( parts )) - 1 + minBlockSize     \n",
    "    cov=None     \n",
    "    for nCols_ in parts:         \n",
    "        cov_=getCovSub(int(max(nCols_*(nCols_+1)/2.,100)),nCols_,sigma,random_state=rng)         \n",
    "        if cov is None:cov=cov_.copy()         \n",
    "        else:cov=block_diag(cov,cov_)     \n",
    "    return cov "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function cov2corr transforms covariance into correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov2corr(cov):     \n",
    "    # Derive the correlation matrix from a covariance matrix     \n",
    "    std=np.sqrt(np.diag(cov))     \n",
    "    corr=cov/np.outer(std,std)     \n",
    "    corr[corr<-1],corr[corr>1]=-1,1 # numerical error     \n",
    "    return corr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function randomBlockCorr forms the random block correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomBlockCorr(nCols,nBlocks,random_state=None,minBlockSize=1):     \n",
    "    # Form block correlation    \n",
    "    rng = check_random_state(random_state)     \n",
    "    cov0=getRndBlockCov(nCols,nBlocks,minBlockSize=minBlockSize,\\\n",
    "                        sigma=.5,random_state=rng) # perfect block corr     \n",
    "    cov1=getRndBlockCov(nCols,1,minBlockSize=minBlockSize,\\\n",
    "                        sigma=1.,random_state=rng) # add noise     \n",
    "    cov0+=cov1     \n",
    "    corr0=cov2corr(cov0)     \n",
    "    corr0=pd.DataFrame(corr0)     \n",
    "    return corr0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Base Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code brings in the base clustering that results in the correlation matrix, the clusters, and the Silhouette scores. The purpose of this step is to perform a first-pass estimate of E[𝐾]. First, we transform the correlation matrix into a distance matrix. On this distance matrix, we apply the K-means algorithm on alternative target number of clusters. For each target number of clusters, we perform a stochastic optimization, repeating the clustering operation n_init times. Among all the clustering alternatives, we choose the solution that achieves the highest quality score, defined as the t-value of the silhouette scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "def clusterKMeansBase(corr0,maxNumClusters=10,n_init=10):     \n",
    "    kmeans = 0\n",
    "    from sklearn.cluster import KMeans     \n",
    "    from sklearn.metrics import silhouette_samples     \n",
    "    dist,silh=((1-corr0.fillna(0))/2.)**.5,pd.Series() # distance matrix     \n",
    "    for init in range(n_init):         \n",
    "        for i in range(2,maxNumClusters+1): # find optimal num clusters             \n",
    "            kmeans_=KMeans(n_clusters=i,n_jobs=1,n_init=1)             \n",
    "            kmeans_=kmeans_.fit(dist)             \n",
    "            silh_=silhouette_samples(dist,kmeans_.labels_)             \n",
    "            stat=(silh_.mean()/silh_.std(),silh.mean()/silh.std())             \n",
    "            if np.isnan(stat[1]) or stat[0]>stat[1]:                 \n",
    "                silh,kmeans=silh_,kmeans_     \n",
    "    n_clusters = len( np.unique( kmeans.labels_ ) )     \n",
    "    newIdx=np.argsort(kmeans.labels_)     \n",
    "    corr1=corr0.iloc[newIdx] # reorder rows     \n",
    "    corr1=corr1.iloc[:,newIdx] # reorder columns     \n",
    "    clstrs={i:corr0.columns[np.where(kmeans.labels_==i)[0] ].tolist() for\\\n",
    "            i in np.unique(kmeans.labels_) } # cluster members     \n",
    "    silh=pd.Series(silh,index=dist.index)     \n",
    "    return corr1,clstrs,silh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Top-Level Clustering Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code performs a second pass-estimate of E[K], the number of clustered trials. We evaluate the quality score for each cluster within the first-pass solution. Those clusters with quality greater or equal than average remain unchanged. We re-run the base clustering on clusters with below-average quality. The outputs of these re-runs are preserved only if their cluster quality improves. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeNewOutputs(corr0,clstrs,clstrs2):     \n",
    "    from sklearn.metrics import silhouette_samples     \n",
    "    clstrsNew,newIdx={},[]     \n",
    "    for i in clstrs.keys():         \n",
    "        clstrsNew[len(clstrsNew.keys())]=list(clstrs[i])     \n",
    "    for i in clstrs2.keys():         \n",
    "        clstrsNew[len(clstrsNew.keys())]=list(clstrs2[i])     \n",
    "    map(newIdx.extend, clstrsNew.values())     \n",
    "    corrNew=corr0.loc[newIdx,newIdx] \n",
    "    dist=((1-corr0.fillna(0))/2.)**.5     \n",
    "    kmeans_labels=np.zeros(len(dist.columns))     \n",
    "    for i in clstrsNew.keys():         \n",
    "        idxs=[dist.index.get_loc(k) for k in clstrsNew[i]]         \n",
    "        kmeans_labels[idxs]=i     \n",
    "    silhNew=pd.Series(silhouette_samples(dist,kmeans_labels),index=dist.index)     \n",
    "    return corrNew,clstrsNew,silhNew \n",
    "#------------------------------------------------------------------------------ \n",
    "\n",
    "def clusterKMeansTop(corr0,maxNumClusters=10,n_init=10):     \n",
    "    corr1,clstrs,silh=clusterKMeansBase(corr0,maxNumClusters=corr0.shape[1]-1,n_init=n_init)     \n",
    "    clusterTstats={i:np.mean(silh[clstrs[i]])/np.std(silh[clstrs[i]]) for i in clstrs.keys()}     \n",
    "    tStatMean=np.mean(list(clusterTstats.values()))     \n",
    "    redoClusters=[i for i in clusterTstats.keys() if clusterTstats[i]<tStatMean]     \n",
    "    if len(redoClusters)<=2:         \n",
    "        return corr1,clstrs,silh     \n",
    "    else:         \n",
    "        keysRedo=[];map(keysRedo.extend,[clstrs[i] for i in redoClusters])         \n",
    "        corrTmp=corr0.loc[keysRedo,keysRedo]         \n",
    "        meanRedoTstat=np.mean([clusterTstats[i] for i in redoClusters])         \n",
    "        corr2,clstrs2,silh2=clusterKMeansTop(corrTmp,\\\n",
    "            maxNumClusters=corrTmp.shape[1]-1,n_init=n_init)         \n",
    "        # Make new outputs, if necessary         \n",
    "        corrNew,clstrsNew,silhNew=makeNewOutputs(corr0,\\\n",
    "            {i:clstrs[i] for i in clstrs.keys() if i not in redoClusters},clstrs2)        \n",
    "        newTstatMean=np.mean([np.mean(silhNew[clstrsNew[i]])/np.std(silhNew[clstrsNew[i]])\\\n",
    "            for i in clstrsNew.keys()])         \n",
    "        if newTstatMean<=meanRedoTstat:             \n",
    "            return corr1,clstrs,silh         \n",
    "        else:             \n",
    "            return corrNew,clstrsNew,silhNew "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set predetermined variables for the algorithm. These values are generated randomly according to necessities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "nBlocks1 = random.randint(1,10)\n",
    "nCols1= random.randint(nBlocks1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the randomBlockCorr function to create a random correlation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomBlockCorr(nCols,nBlocks,random_state=None,minBlockSize=1)\n",
    "corr0A=randomBlockCorr(nCols1,nBlocks1,random_state=None,minBlockSize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.299803</td>\n",
       "      <td>0.367218</td>\n",
       "      <td>0.353776</td>\n",
       "      <td>0.320724</td>\n",
       "      <td>0.333638</td>\n",
       "      <td>0.287385</td>\n",
       "      <td>0.248304</td>\n",
       "      <td>0.295062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.299803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.580793</td>\n",
       "      <td>0.313102</td>\n",
       "      <td>0.317575</td>\n",
       "      <td>0.235510</td>\n",
       "      <td>0.264361</td>\n",
       "      <td>0.305430</td>\n",
       "      <td>0.315029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.367218</td>\n",
       "      <td>0.580793</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.282453</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.282295</td>\n",
       "      <td>0.261318</td>\n",
       "      <td>0.281958</td>\n",
       "      <td>0.317544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.353776</td>\n",
       "      <td>0.313102</td>\n",
       "      <td>0.282453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.650832</td>\n",
       "      <td>0.603599</td>\n",
       "      <td>0.629012</td>\n",
       "      <td>0.601470</td>\n",
       "      <td>0.581284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.320724</td>\n",
       "      <td>0.317575</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.650832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.598514</td>\n",
       "      <td>0.610589</td>\n",
       "      <td>0.592051</td>\n",
       "      <td>0.596937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.299803  0.367218  0.353776  0.320724  0.333638  0.287385   \n",
       "1  0.299803  1.000000  0.580793  0.313102  0.317575  0.235510  0.264361   \n",
       "2  0.367218  0.580793  1.000000  0.282453  0.270105  0.282295  0.261318   \n",
       "3  0.353776  0.313102  0.282453  1.000000  0.650832  0.603599  0.629012   \n",
       "4  0.320724  0.317575  0.270105  0.650832  1.000000  0.598514  0.610589   \n",
       "\n",
       "          7         8  \n",
       "0  0.248304  0.295062  \n",
       "1  0.305430  0.315029  \n",
       "2  0.281958  0.317544  \n",
       "3  0.601470  0.581284  \n",
       "4  0.592051  0.596937  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr0A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the Top-Level Clustering Algorithm that yields in: \n",
    "\n",
    "* Correlation Matrix\n",
    "* Optimized Clusters\n",
    "* Silhouette Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          3         4         5         6         7         8         0  \\\n",
       " 3  1.000000  0.650832  0.603599  0.629012  0.601470  0.581284  0.353776   \n",
       " 4  0.650832  1.000000  0.598514  0.610589  0.592051  0.596937  0.320724   \n",
       " 5  0.603599  0.598514  1.000000  0.570831  0.631035  0.565898  0.333638   \n",
       " 6  0.629012  0.610589  0.570831  1.000000  0.635946  0.582609  0.287385   \n",
       " 7  0.601470  0.592051  0.631035  0.635946  1.000000  0.651579  0.248304   \n",
       " 8  0.581284  0.596937  0.565898  0.582609  0.651579  1.000000  0.295062   \n",
       " 0  0.353776  0.320724  0.333638  0.287385  0.248304  0.295062  1.000000   \n",
       " 1  0.313102  0.317575  0.235510  0.264361  0.305430  0.315029  0.299803   \n",
       " 2  0.282453  0.270105  0.282295  0.261318  0.281958  0.317544  0.367218   \n",
       " \n",
       "           1         2  \n",
       " 3  0.313102  0.282453  \n",
       " 4  0.317575  0.270105  \n",
       " 5  0.235510  0.282295  \n",
       " 6  0.264361  0.261318  \n",
       " 7  0.305430  0.281958  \n",
       " 8  0.315029  0.317544  \n",
       " 0  0.299803  0.367218  \n",
       " 1  1.000000  0.580793  \n",
       " 2  0.580793  1.000000  , {0: [3, 4, 5, 6, 7, 8], 1: [0, 1, 2]}, 0    0.077754\n",
       " 1    0.187427\n",
       " 2    0.214416\n",
       " 3    0.310942\n",
       " 4    0.311913\n",
       " 5    0.300458\n",
       " 6    0.320191\n",
       " 7    0.335175\n",
       " 8    0.292043\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clusterKMeansTop(corr0,maxNumClusters=10,n_init=10)\n",
    "clusterKMeansTop(corr0A,maxNumClusters=10,n_init=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of ONC can be seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency checking with the package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check the consistency between the above steps on ONC with the mlfinlab ONC package that is known as get_onc_clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlfinlab.clustering.onc import get_onc_clusters # import the ONC function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = get_onc_clusters(corr0A,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          3         4         5         6         7         8         0  \\\n",
       " 3  1.000000  0.650832  0.603599  0.629012  0.601470  0.581284  0.353776   \n",
       " 4  0.650832  1.000000  0.598514  0.610589  0.592051  0.596937  0.320724   \n",
       " 5  0.603599  0.598514  1.000000  0.570831  0.631035  0.565898  0.333638   \n",
       " 6  0.629012  0.610589  0.570831  1.000000  0.635946  0.582609  0.287385   \n",
       " 7  0.601470  0.592051  0.631035  0.635946  1.000000  0.651579  0.248304   \n",
       " 8  0.581284  0.596937  0.565898  0.582609  0.651579  1.000000  0.295062   \n",
       " 0  0.353776  0.320724  0.333638  0.287385  0.248304  0.295062  1.000000   \n",
       " 1  0.313102  0.317575  0.235510  0.264361  0.305430  0.315029  0.299803   \n",
       " 2  0.282453  0.270105  0.282295  0.261318  0.281958  0.317544  0.367218   \n",
       " \n",
       "           1         2  \n",
       " 3  0.313102  0.282453  \n",
       " 4  0.317575  0.270105  \n",
       " 5  0.235510  0.282295  \n",
       " 6  0.264361  0.261318  \n",
       " 7  0.305430  0.281958  \n",
       " 8  0.315029  0.317544  \n",
       " 0  0.299803  0.367218  \n",
       " 1  1.000000  0.580793  \n",
       " 2  0.580793  1.000000  , {0: [3, 4, 5, 6, 7, 8], 1: [0, 1, 2]}, 0    0.077754\n",
       " 1    0.187427\n",
       " 2    0.214416\n",
       " 3    0.310942\n",
       " 4    0.311913\n",
       " 5    0.300458\n",
       " 6    0.320191\n",
       " 7    0.335175\n",
       " 8    0.292043\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The step by step results in the exercises have the same consistency as the ONC mlfinlab package results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
